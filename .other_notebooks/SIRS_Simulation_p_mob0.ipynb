{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import networkx as nx\n",
    "from IPython.display import display, clear_output\n",
    "from scipy import signal\n",
    "from scipy import fftpack\n",
    "from numpy.fft import fft, fftfreq\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# import custom module\n",
    "import SIRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed only if you made some changes at SIRS.py and want to import the updated version of the module\n",
    "from importlib import reload\n",
    "reload(SIRS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOOKING FOR CRITICAL VALUES OF THE DESEASE PARAMETERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These parameters correspond to those of seasonal flu, in particular:\n",
    "\n",
    "$$R_0 \\in [0.9, 2.1]$$\n",
    "recovery time $\\in$ [5,7] so\n",
    "$$\\rightarrow \\mu \\in [0.143,0.2]$$\n",
    "probability of contagion GIVEN contact \n",
    "$$\\beta = R_0 \\mu \\in [0.128, 0.42]$$\n",
    "\n",
    "\n",
    "If we raughly consider averages this value of $\\beta$, in order to be used in our framework including topology, must be divided by the mean degree of the network $<k>$, so that $\\widetilde{\\beta} = \\frac{\\beta}{<k>}$ and the probability that a susceptible node gets infected can be computed as  \n",
    "$P(I \\rightarrow S) = \\widetilde{\\beta} \\cdot [number\\_of\\_susceptible\\_neightbours]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mobility and topology parameters\n",
    "N = 1000\n",
    "I_sf_init = 5\n",
    "I_er_init = 5\n",
    "p_mob = 0\n",
    "mean_degree = 4\n",
    "eps = 0.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epidemics values\n",
    "beta = 0.3/mean_degree #mean degree of generated networks is usually a little smaller\n",
    "mu = 0.15\n",
    "gamma = 0.016\n",
    "\n",
    "R_0 = beta/mu\n",
    "    \n",
    "print(\"Basic Reproductive Ratio (taking into account topology):\", R_0)\n",
    "print(\"\\u03B2 (taking into account topology):\", beta)\n",
    "\n",
    "\n",
    "infection_params = dict(beta=beta, mu=mu, gamma=gamma)\n",
    "\n",
    "\n",
    "directory_name = str(beta)+\"_\"+str(mu)+\"_\"+str(gamma) \n",
    "os.system(\"mkdir \"+directory_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This $\\gamma$ value corresponds to an average time for going from R to S of 60 \"days\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_runs = 30\n",
    "n_iter = 1000\n",
    "\n",
    "save_data = False\n",
    "every_graph = 1\n",
    "\n",
    "S_tot_er=0*(n_iter+1)\n",
    "I_tot_er=0*(n_iter+1)\n",
    "R_tot_er=0*(n_iter+1)\n",
    "S_tot_sf=0*(n_iter+1)\n",
    "I_tot_sf=0*(n_iter+1)\n",
    "R_tot_sf=0*(n_iter+1)\n",
    "\n",
    "\n",
    "for run in range(n_runs):   \n",
    "    \n",
    "    # prepare systems\n",
    "    state_sf_init, state_er_init, variables_net_sf, variables_net_er = SIRS.prepare_two_sys(N, I_sf_init, I_er_init, \n",
    "                                                                                  p_mob, mean_degree)\n",
    "    \n",
    "    #saving initial states\n",
    "    save = directory_name + \"/state_sf_init_\"+str(run)+\".txt\"\n",
    "    np.savetxt(save, state_sf_init)\n",
    "\n",
    "    save = directory_name + \"/state_er_init_\"+str(run)+\".txt\"\n",
    "    np.savetxt(save, state_er_init)\n",
    "\n",
    "    #saving initial variables: we just save the IDs of the travelling nodes and the initial network \n",
    "    #(as adjacency matrix)\n",
    "    save = directory_name + \"/A_sf_\"+str(run)+\".txt\"\n",
    "    np.savetxt(save, variables_net_sf[\"A_sf\"])\n",
    "    save = directory_name + \"/A_er_\"+str(run)+\".txt\"\n",
    "    np.savetxt(save, variables_net_er[\"A_er\"])\n",
    "\n",
    "\n",
    "    save = directory_name + \"/travellers_sf_\"+str(run)+\".txt\"\n",
    "    np.savetxt(save, variables_net_sf[\"travellers_sf\"])\n",
    "    save = directory_name + \"/travellers_er_\"+str(run)+\".txt\"\n",
    "    np.savetxt(save, variables_net_er[\"travellers_er\"])\n",
    "\n",
    "\n",
    "    state_sf = np.copy(state_sf_init)\n",
    "    state_er = np.copy(state_er_init)\n",
    "\n",
    "    import time \n",
    "    start = time.time()\n",
    "    S_sf = [N - I_sf_init]\n",
    "    I_sf = [I_sf_init]\n",
    "    R_sf = [0]\n",
    "    S_er = [N - I_er_init]\n",
    "    I_er = [I_er_init]\n",
    "    R_er = [0]\n",
    "    t_vec = []\n",
    "    for i in range(n_iter):\n",
    "        state_sf, state_er = SIRS.two_sys_full_SIRS_step(state_sf, state_er, **variables_net_sf, \n",
    "                                                **variables_net_er, **infection_params)\n",
    "        S_sf.append(state_sf[:,0].sum())\n",
    "        I_sf.append(state_sf[:,1].sum())\n",
    "        R_sf.append(state_sf[:,2].sum())\n",
    "        S_er.append(state_er[:,0].sum())\n",
    "        I_er.append(state_er[:,1].sum())\n",
    "        R_er.append(state_er[:,2].sum())\n",
    "        t_vec.append(time.time()-start)\n",
    "\n",
    "    tot_time = time.time()-start\n",
    "    print(\"Total time elapsed: %.2f s\"%tot_time)\n",
    "    print(\"Time per iteration: %.4f s\"%(tot_time/n_iter))\n",
    "\n",
    "    S_sf = np.array(S_sf)\n",
    "    I_sf = np.array(I_sf)\n",
    "    R_sf = np.array(R_sf)\n",
    "    S_er = np.array(S_er)\n",
    "    I_er = np.array(I_er)\n",
    "    R_er = np.array(R_er)\n",
    "    t_vec = np.array(t_vec)\n",
    "    \n",
    "    if seva_data == True:\n",
    "    \n",
    "        #save timeseries of SIR\n",
    "        SIR_sf = np.vstack((S_sf, I_sf, R_sf)).T\n",
    "        save = directory_name+\"/SIR_sf_\"+str(run)+\".txt\"\n",
    "        np.savetxt(save, SIR_sf)\n",
    "        SIR_er = np.vstack((S_er, I_er, R_er)).T\n",
    "        save = directory_name+\"/SIR_er_\"+str(run)+\".txt\"\n",
    "        np.savetxt(save, SIR_er)\n",
    "    \n",
    "    S_tot_sf+=S_sf\n",
    "    I_tot_sf+=I_sf\n",
    "    R_tot_sf+=R_sf\n",
    "    S_tot_er+=S_er\n",
    "    I_tot_er+=I_er\n",
    "    R_tot_er+=R_er\n",
    "    \n",
    "    if (run%every_graph==0): #plots every every_graph graphs\n",
    "\n",
    "        indexes = np.arange(n_iter+1)\n",
    "        fig, ax = plt.subplots(1,2, figsize=(15,8))\n",
    "        ax[0].plot(indexes, S_sf, label = r'$S_{sf}$')\n",
    "        ax[0].plot(indexes, I_sf, label = r'$I_{sf}$')\n",
    "        ax[0].plot(indexes, R_sf, label = r'$R_{sf}$')\n",
    "        ax[0].plot(indexes, S_sf+I_sf+R_sf, label = 'tot')\n",
    "        ax[0].set_xlabel('Number of iterations', fontsize = 16)\n",
    "        ax[0].set_ylabel('Number of individuals', fontsize = 16)\n",
    "        ax[0].set_title(\"Scale-free network\", fontsize = 16)\n",
    "        ax[0].legend(fontsize=13, loc='upper right')\n",
    "\n",
    "        ax[1].plot(indexes, S_er, label = r'$S_{er}$')\n",
    "        ax[1].plot(indexes, I_er, label = r'$I_{er}$')\n",
    "        ax[1].plot(indexes, R_er, label = r'$R_{er}$')\n",
    "        ax[1].plot(indexes, S_er+I_er+R_er, label = 'tot')\n",
    "        ax[1].set_title(\"Erdosh-Renyi network\", fontsize = 16)\n",
    "        ax[1].set_xlabel('Number of iterations', fontsize = 16)\n",
    "        ax[1].set_ylabel('Number of individuals', fontsize = 16)\n",
    "        ax[1].legend(fontsize=13, loc='upper right')\n",
    "\n",
    "        plt.suptitle(r\"$\\beta= {:.3f}; \\mu= {:.3f}; \\gamma= {:.3f}$\".format(beta, mu, gamma), fontsize=20)\n",
    "\n",
    "        save=directory_name+\"/run_\"+str(run)+\".png\"\n",
    "        fig.savefig(save)\n",
    "        plt.close()\n",
    "    \n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(15,8))\n",
    "ax[0].plot(indexes, S_tot_sf/n_runs, label = r'$S_{sf}$')\n",
    "ax[0].plot(indexes, I_tot_sf/n_runs, label = r'$I_{sf}$')\n",
    "ax[0].plot(indexes, R_tot_sf/n_runs, label = r'$R_{sf}$')\n",
    "ax[0].plot(indexes, (S_tot_sf+I_tot_sf+R_tot_sf)/n_runs, label = 'tot')\n",
    "ax[0].set_xlabel('Number of iterations', fontsize = 16)\n",
    "ax[0].set_ylabel('Number of individuals', fontsize = 16)\n",
    "ax[0].set_title(\"Scale-free network\", fontsize = 16)\n",
    "ax[0].legend(fontsize=13, loc='upper right')\n",
    "\n",
    "ax[1].plot(indexes, S_tot_er/n_runs, label = r'$S_{er}$')\n",
    "ax[1].plot(indexes, I_tot_er/n_runs, label = r'$I_{er}$')\n",
    "ax[1].plot(indexes, R_tot_er/n_runs, label = r'$R_{er}$')\n",
    "ax[1].plot(indexes, (S_tot_er+I_tot_er+R_tot_er)/n_runs, label = 'tot')\n",
    "ax[1].set_title(\"Erdosh-Renyi network\", fontsize = 16)\n",
    "ax[1].set_xlabel('Number of iterations', fontsize = 16)\n",
    "ax[1].set_ylabel('Number of individuals', fontsize = 16)\n",
    "ax[1].legend(fontsize=13, loc='upper right')\n",
    "\n",
    "plt.suptitle(r\"Mean on {} runs, $\\beta= {:.3f}; \\mu= {:.3f}; \\gamma= {:.3f}$\".format(n_runs, beta, mu, gamma), fontsize=20)\n",
    "\n",
    "save = directory_name+\"/total.png\"\n",
    "fig.savefig(save)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#saving stuff for future analysis\n",
    "directory_name = str(beta)+\"_\"+str(mu)+\"_\"+str(gamma) \n",
    "os.system(\"mkdir \"+directory_name)\n",
    "\n",
    "#saving epidemics, topology and mobility parameters\n",
    "\n",
    "params=dict(N=N, I_sf_init=I_sf_init, I_er_nit=I_er_init, p_mob=p_mob, mean_degree=mean_degree,\n",
    "            eps=eps, **infection_params)\n",
    "\n",
    "parameters = pd.DataFrame(params, index=[0])\n",
    "save=directory_name+\"/parameters.csv\"\n",
    "parameters.to_csv(save)\n",
    "\n",
    "#saving initial states\n",
    "save = directory_name + \"/state_sf_init.txt\"\n",
    "np.savetxt(save, state_sf_init)\n",
    "\n",
    "save = directory_name + \"/state_er_init.txt\"\n",
    "np.savetxt(save, state_sf_init)\n",
    "\n",
    "#saving initial variables: we just save the IDs of the travelling nodes and the initial network \n",
    "#(as adjacency matrix)\n",
    "save = directory_name + \"/A_sf.txt\"\n",
    "np.savetxt(save, variables_net_sf[\"A_sf\"])\n",
    "save = directory_name + \"/A_er.txt\"\n",
    "np.savetxt(save, variables_net_er[\"A_er\"])\n",
    "\n",
    "\n",
    "save = directory_name + \"/travellers_sf.txt\"\n",
    "np.savetxt(save, variables_net_sf[\"travellers_sf\"])\n",
    "save = directory_name + \"/travellers_er.txt\"\n",
    "np.savetxt(save, variables_net_er[\"travellers_er\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
