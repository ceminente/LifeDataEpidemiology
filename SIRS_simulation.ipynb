{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import networkx as nx\n",
    "from IPython.display import display, clear_output\n",
    "from scipy import signal\n",
    "from scipy import fftpack\n",
    "from numpy.fft import fft, fftfreq\n",
    "import os\n",
    "import pandas as pd\n",
    "import time \n",
    "\n",
    "# import custom module\n",
    "import SIRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'SIRS' from '/home/clara/OneDrive/Università/Terzo Semestre/Life Data Epidemiology/LDE_project/LifeDataEpidemiology/SIRS.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# needed only if you made some changes at SIRS.py and want to import the updated version of the module\n",
    "from importlib import reload\n",
    "reload(SIRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to install tqdm\n",
    "#! pip install tqdm\n",
    "\n",
    "from tqdm import tnrange, trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STARTING TO EXPLORE MOBILITY: changing probability of travel p_mob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fixed the epidemic parameters in a \"critical\" point at which most of the times the epidemics does not survive and dies out after some iterations. The topology of the two networks is also kept fixed. We now explore the role of the mobility parameter p_mob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mobility and topology parameters\n",
    "N = 1000\n",
    "I_sf_init = 5\n",
    "I_er_init = 0\n",
    "mean_degree = 4\n",
    "eps = 0.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of travellers:\n",
      "p=0.03    N=30\n",
      "p=0.04    N=38\n",
      "p=0.05    N=47\n",
      "p=0.06    N=56\n",
      "p=0.07    N=65\n",
      "p=0.07    N=74\n",
      "p=0.08    N=83\n",
      "p=0.09    N=92\n",
      "p=0.10    N=101\n",
      "p=0.11    N=110\n"
     ]
    }
   ],
   "source": [
    "#beta_list = [0.3]\n",
    "#gamma_list = [0.02]\n",
    "beta0 = 0.3\n",
    "gamma = 0.02\n",
    "mu = 0.15\n",
    "\n",
    "p_mob_list = np.linspace(0.03,0.2,20)\n",
    "#p_mob_list_nico = p_mob_list[10:]\n",
    "#p_mob_list_clara = p_mob_list[:10]\n",
    "p_mob_list = p_mob_list[:10]\n",
    "print('Number of travellers:')\n",
    "for p in p_mob_list:\n",
    "    print('p=%.2f    N=%d'%(p, int(p*N)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation 1/20 - P_mob: 0.030\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa438b1c6a994610bd5f71525035b962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='1st loop', max=2, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='2nd loop', style=ProgressStyle(description_width='initial')),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='2nd loop', style=ProgressStyle(description_width='initial')),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time elapsed: 0.00 - ETA: 0.04\n",
      "Simulation 2/20 - P_mob: 0.039\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c1090d36cb40bcbc3d56bd1d13e0f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='1st loop', max=2, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f811d01bf21149b986463e9046f8c1ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='2nd loop', style=ProgressStyle(description_width='initial')),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-efa1f57f0fe6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtnrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2nd loop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             state_sf, state_er = SIRS.two_sys_full_SIRS_step(state_sf, state_er, **variables_net_sf, \n\u001b[0;32m--> 100\u001b[0;31m                                                     **variables_net_er, **infection_params)\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0mS_sf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_sf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mI_sf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_sf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nicola_unipd/QuintoAnno/Life Data Epidemiology/Project/LDE_project/SIRS.py\u001b[0m in \u001b[0;36mtwo_sys_full_SIRS_step\u001b[0;34m(state_sf, state_er, travellers_sf, travellers_er, original_er_net, original_sf_net, new_ids_sf, new_ids_er, deg_sf, deg_er, A_sf, A_er, G_sf_stay, G_er_stay, beta, mu, gamma)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;31m# compute day networks: attach travellers to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m     \u001b[0mA_sf_day\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattach_travellers_sf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_sf_stay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_ids_er\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeg_er\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_tot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m     \u001b[0mA_er_day\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattach_travellers_er\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_er_stay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_ids_sf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeg_sf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_tot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nicola_unipd/QuintoAnno/Life Data Epidemiology/Project/LDE_project/SIRS.py\u001b[0m in \u001b[0;36mattach_travellers_sf\u001b[0;34m(G_sf_stay, new_ids_er, deg_er, N_tot)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeg_er\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#degree of the node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m#this part chooses the new neightbour using an approach that works both for preferential attachment than for ER networks: if i firstly select a certain number of edges between the edges list (indexes=..., see below) if a node makes a lot of connections I have more probability to pick it (preferential attachment). As for random attachment, is it equivalent?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_list_sf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#chooses k links among the edges of the target net\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0medges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_list_sf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#pairs the id with one link at random in the edge (again, if one of the links has a lot of connections it will be more likely for it to be picked)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0medge_list_sf\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0medges\u001b[0m \u001b[0;31m# concatenate new edges\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "beta = beta0/mean_degree\n",
    "infection_params = dict(beta=beta, mu=mu, gamma=gamma)\n",
    "\n",
    "#R_0 = beta/mu\n",
    "\n",
    "#print(\"Basic Reproductive Ratio (taking into account topology):\", R_0)\n",
    "#print(\"\\u03B2 (taking into account topology):\", beta)\n",
    "\n",
    "\n",
    "UP_directory_name = 'data/'+str(beta)+\"_\"+str(mu)+\"_\"+str(gamma) \n",
    "os.system(\"mkdir data\")\n",
    "os.system(\"mkdir \"+UP_directory_name)\n",
    "start = time.time()\n",
    "\n",
    "for j, p_mob in enumerate(p_mob_list):\n",
    "\n",
    "    print('Simulation %d/%d'%(j+1,len(p_mob_list)), end =' - ')\n",
    "    print(\"P_mob: %.3f\"% p_mob)\n",
    "\n",
    "\n",
    "    #saving stuff for future analysis\n",
    "    directory_name = UP_directory_name+\"/pmob_\"+\"{:3f}\".format(p_mob)\n",
    "    os.system(\"mkdir \"+directory_name)\n",
    "\n",
    "    #saving epidemics, topology and mobility parameters\n",
    "\n",
    "    params=dict(N=N, I_sf_init=I_sf_init, I_er_nit=I_er_init, p_mob=p_mob, mean_degree=mean_degree,\n",
    "                eps=eps, **infection_params)\n",
    "\n",
    "    parameters = pd.DataFrame(params, index=[0])\n",
    "    save=directory_name+\"/parameters.csv\"\n",
    "    parameters.to_csv(save)\n",
    "\n",
    "\n",
    "\n",
    "    #STARTING SIMULATION\n",
    "    n_runs = 100\n",
    "    n_iter = 1000\n",
    "\n",
    "\n",
    "    S_tot_er=0\n",
    "    I_tot_er=0\n",
    "    R_tot_er=0\n",
    "    S_tot_sf=0\n",
    "    I_tot_sf=0\n",
    "    R_tot_sf=0\n",
    "\n",
    "\n",
    "    for run in tnrange(n_runs, desc='1st loop', leave=True):\n",
    "\n",
    "\n",
    "        # prepare systems\n",
    "        state_sf_init, state_er_init, variables_net_sf, variables_net_er = SIRS.prepare_two_sys(N, I_sf_init, I_er_init, \n",
    "                                                                                      p_mob, mean_degree)\n",
    "\n",
    "        #saving initial states\n",
    "        save = directory_name + \"/state_sf_init_\"+str(run)+\".txt\"\n",
    "        np.savetxt(save, state_sf_init.astype(int), fmt ='%d')\n",
    "\n",
    "        save = directory_name + \"/state_er_init_\"+str(run)+\".txt\"\n",
    "        np.savetxt(save, state_sf_init.astype(int), fmt ='%d')\n",
    "\n",
    "        save = directory_name + \"/travellers_sf_\"+str(run)+\".txt\"\n",
    "        travellers_sf = variables_net_sf[\"travellers_sf\"]\n",
    "        np.savetxt(save, travellers_sf.astype(int), fmt ='%d')\n",
    "        \n",
    "        save = directory_name + \"/travellers_er_\"+str(run)+\".txt\"\n",
    "        travellers_er = variables_net_er[\"travellers_er\"]\n",
    "        np.savetxt(save, travellers_er.astype(int), fmt ='%d')\n",
    "        \n",
    "        #saving initial variables: we just save the IDs of the travelling nodes and their degrees\n",
    "        save = directory_name + \"/deg_trav_sf_\"+str(run)+\".txt\"\n",
    "        deg_sf = variables_net_sf[\"A_sf\"].sum(axis=1)\n",
    "        deg_trav_sf = deg_sf[travellers_sf]\n",
    "        np.savetxt(save, deg_trav_sf.astype(int), fmt ='%d')\n",
    "        \n",
    "        save = directory_name + \"/deg_trav_er_\"+str(run)+\".txt\"\n",
    "        deg_er = variables_net_er[\"A_er\"].sum(axis=1)\n",
    "        deg_trav_er = deg_er[travellers_er]\n",
    "        np.savetxt(save, deg_trav_er.astype(int), fmt ='%d')\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        #print(\"Iteration:\", run)\n",
    "\n",
    "        state_sf = np.copy(state_sf_init)\n",
    "        state_er = np.copy(state_er_init)\n",
    "\n",
    "        S_sf = [N - I_sf_init]\n",
    "        I_sf = [I_sf_init]\n",
    "        R_sf = [0]\n",
    "        S_er = [N - I_er_init]\n",
    "        I_er = [I_er_init]\n",
    "        R_er = [0]\n",
    "        t_vec = []\n",
    "        for i in tnrange(n_iter, desc='2nd loop', leave=False):\n",
    "            state_sf, state_er = SIRS.two_sys_full_SIRS_step(state_sf, state_er, **variables_net_sf, \n",
    "                                                    **variables_net_er, **infection_params)\n",
    "            S_sf.append(state_sf[:,0].sum())\n",
    "            I_sf.append(state_sf[:,1].sum())\n",
    "            R_sf.append(state_sf[:,2].sum())\n",
    "            S_er.append(state_er[:,0].sum())\n",
    "            I_er.append(state_er[:,1].sum())\n",
    "            R_er.append(state_er[:,2].sum())\n",
    "            #t_vec.append(time.time()-start)\n",
    "\n",
    "        #tot_time = time.time()-start\n",
    "        #print(\"Total time elapsed: %.2f s\"%tot_time)\n",
    "        #print(\"Time per iteration: %.4f s\"%(tot_time/n_iter))\n",
    "\n",
    "        S_sf = np.array(S_sf)\n",
    "        I_sf = np.array(I_sf)\n",
    "        R_sf = np.array(R_sf)\n",
    "        S_er = np.array(S_er)\n",
    "        I_er = np.array(I_er)\n",
    "        R_er = np.array(R_er)\n",
    "        t_vec = np.array(t_vec)\n",
    "\n",
    "        #save timeseries of SIR\n",
    "        SIR_sf = np.vstack((S_sf, I_sf, R_sf)).T\n",
    "        save = directory_name+\"/SIR_sf_\"+str(run)+\".txt\"\n",
    "        np.savetxt(save, SIR_sf.astype(int), fmt ='%d')\n",
    "        SIR_er = np.vstack((S_er, I_er, R_er)).T\n",
    "        save = directory_name+\"/SIR_er_\"+str(run)+\".txt\"\n",
    "        np.savetxt(save, SIR_er.astype(int), fmt ='%d')\n",
    "        \n",
    "        # broadcast S_tot_sf (and all the others) to numpy arrays\n",
    "        S_tot_sf+=S_sf\n",
    "        I_tot_sf+=I_sf\n",
    "        R_tot_sf+=R_sf\n",
    "        S_tot_er+=S_er\n",
    "        I_tot_er+=I_er\n",
    "        R_tot_er+=R_er\n",
    "\n",
    "\n",
    "\n",
    "    indexes = np.arange(n_iter+1)\n",
    "    fig, ax = plt.subplots(1,2, figsize=(15,8))\n",
    "    ax[0].plot(indexes, S_tot_sf/n_runs, label = r'$S_{sf}$')\n",
    "    ax[0].plot(indexes, I_tot_sf/n_runs, label = r'$I_{sf}$')\n",
    "    ax[0].plot(indexes, R_tot_sf/n_runs, label = r'$R_{sf}$')\n",
    "    ax[0].plot(indexes, (S_tot_sf+I_tot_sf+R_tot_sf)/n_runs, label = 'tot')\n",
    "    ax[0].set_xlabel('Number of iterations', fontsize = 16)\n",
    "    ax[0].set_ylabel('Number of individuals', fontsize = 16)\n",
    "    ax[0].set_title(\"Scale-free network\", fontsize = 16)\n",
    "    ax[0].legend(fontsize=13, loc='upper right')\n",
    "\n",
    "    ax[1].plot(indexes, S_tot_er/n_runs, label = r'$S_{er}$')\n",
    "    ax[1].plot(indexes, I_tot_er/n_runs, label = r'$I_{er}$')\n",
    "    ax[1].plot(indexes, R_tot_er/n_runs, label = r'$R_{er}$')\n",
    "    ax[1].plot(indexes, (S_tot_er+I_tot_er+R_tot_er)/n_runs, label = 'tot')\n",
    "    ax[1].set_title(\"Erdosh-Renyi network\", fontsize = 16)\n",
    "    ax[1].set_xlabel('Number of iterations', fontsize = 16)\n",
    "    ax[1].set_ylabel('Number of individuals', fontsize = 16)\n",
    "    ax[1].legend(fontsize=13, loc='upper right')\n",
    "\n",
    "\n",
    "\n",
    "    plt.suptitle(r\"Mean on {} runs, p_mob = {:.3f}; $\\beta= {:.3f}; \\mu= {:.3f}; \\gamma= {:.3f}$\".format(n_runs, p_mob, mu, beta, gamma), fontsize=20)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    save = directory_name+\"/total_\"+str(p_mob)+\".png\"\n",
    "    fig.savefig(save)\n",
    "    plt.close()\n",
    "    \n",
    "    dt = (time.time() - start)/3600\n",
    "    # estimated time of arrival\n",
    "    eta = (dt/(j+1))*(len(p_mob_list)-j-1)\n",
    "    print(\"Total time elapsed: %.2f - ETA: %.2f\"%(dt, eta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
